{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
   "metadata": {
    "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
   },
   "source": [
    "# SQL query from table names - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03f026a",
   "metadata": {
    "id": "a03f026a"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
   "metadata": {
    "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
   },
   "source": [
    "## The old Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922f8d24",
   "metadata": {
    "id": "922f8d24"
   },
   "outputs": [],
   "source": [
    "#The old prompt\n",
    "old_context = [ {'role':'system', 'content':\"\"\"\n",
    "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
    "this is your SQL, and after that an SQL that can do what the user request. \\\n",
    "Your Database is composed by a SQL database with some tables. \\\n",
    "Try to maintain the SQL order simple.\n",
    "Put the SQL command in white letters with a black background, and just after \\\n",
    "a simple and concise text explaining how it works.\n",
    "If the user ask for something that can not be solved with an SQL Order \\\n",
    "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
    "can be solved with SQL.\n",
    "\"\"\"} ]\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "first table:\n",
    "{\n",
    "  \"tableName\": \"employees\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"tipo\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"nombre\": \"name\",\n",
    "      \"tipo\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "second table:\n",
    "{\n",
    "  \"tableName\": \"salary\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"type\": \"date\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"salary\",\n",
    "      \"type\": \"float\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "third table:\n",
    "{\n",
    "  \"tablename\": \"studies\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"ID\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"educational_level\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Institution\",\n",
    "      \"type\": \"varchar\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Years\",\n",
    "      \"type\": \"date\"\n",
    "    }\n",
    "    {\n",
    "      \"name\": \"Speciality\",\n",
    "      \"type\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377acaae-7dd0-4d13-bc68-9e33741c231c",
   "metadata": {
    "id": "377acaae-7dd0-4d13-bc68-9e33741c231c"
   },
   "source": [
    "## New Prompt.\n",
    "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
    "\n",
    "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
    "\n",
    "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5334f942",
   "metadata": {
    "id": "5334f942"
   },
   "outputs": [],
   "source": [
    "context = [ {'role':'system', 'content':\"\"\"\n",
    " CREATE SEVERAL (3+) TABLES HERE\n",
    "\"\"\"} ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
   "metadata": {
    "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
   },
   "outputs": [],
   "source": [
    "#FEW SHOT SAMPLES\n",
    "context.append( {'role':'system', 'content':\"\"\"\n",
    " -- Maintain the SQL order simple and efficient as you can, using valid SQL Lite, answer the following questions for the table provided above.\n",
    "WRITE IN YOUR CONTEXT QUERIES HERE\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90f417a",
   "metadata": {
    "id": "b90f417a"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
   "metadata": {
    "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
   },
   "source": [
    "## NL2SQL Samples\n",
    "We're going to review some examples generated with the old prompt and others with the new prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59e8202c-ce34-487e-9037-c65a263423ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59e8202c-ce34-487e-9037-c65a263423ed",
    "outputId": "f7a97b9f-45d7-4f78-8979-a796c5bc42fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT name\n",
      "FROM employees\n",
      "ORDER BY salary DESC\n",
      "LIMIT 1;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"\"\"the highest paid employee's name\"\"\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
    "outputId": "029844da-5f1f-4f65-9adb-4d9c1cafacea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT e.name\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_usr = s.ID_usr\n",
      "ORDER BY s.salary DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "This SQL query selects the name of the employee who has the highest salary by joining the \"employees\" table with the \"salary\" table on the ID_usr field. It then orders the result by salary in descending order and limits the output to only one row, which corresponds to the highest-paid employee.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"highest-paid employee's name\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
    "outputId": "2934cdec-bea0-44db-b047-33e70dcf8ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT institution_name, AVG(salary) AS average_salary\n",
      "FROM graduates\n",
      "GROUP BY institution_name\n",
      "ORDER BY average_salary DESC\n",
      "LIMIT 1;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "print(return_CCRMSQL(\"institution whose graduates have the highest average salary\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
    "outputId": "605724a1-0d89-4ed9-d8ec-1aeeae6dc287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT s.Institution, AVG(sa.salary) AS avg_salary\n",
      "FROM studies s\n",
      "JOIN employees e ON s.ID_usr = e.ID_usr\n",
      "JOIN salary sa ON s.ID_usr = sa.ID_usr\n",
      "GROUP BY s.Institution\n",
      "ORDER BY avg_salary DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "This SQL query joins the tables `studies`, `employees`, and `salary` based on the user ID. It calculates the average salary for each institution by grouping the results by institution. Then, it orders the results by average salary in descending order and limits the output to show only the institution with the highest average salary.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "print(return_CCRMSQL(\"institution whose graduates have the highest average salary\", old_context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47",
   "metadata": {
    "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
    "     - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dda9c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query 1: highest paid employee's name ---\n",
      "t0 Prompt Result:\n",
      "```sql\n",
      "SELECT e.name\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_usr = s.ID_usr\n",
      "WHERE s.salary = (SELECT MAX(salary) FROM salary);\n",
      "```\n",
      "simple Prompt Result:\n",
      "```sql\n",
      "SELECT e.name\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_usr = s.ID_usr\n",
      "WHERE s.salary = (SELECT MAX(salary) FROM salary);\n",
      "```\n",
      "t1 Prompt Result:\n",
      "```sql\n",
      "SELECT name\n",
      "FROM employees\n",
      "ORDER BY salary DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "--- Query 2: institution whose graduates have the highest average salary ---\n",
      "t0 Prompt Result:\n",
      "```sql\n",
      "SELECT s.Institution\n",
      "FROM studies st\n",
      "JOIN salary s ON st.ID_usr = s.ID_usr\n",
      "GROUP BY st.Institution\n",
      "ORDER BY AVG(s.salary) DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "simple Prompt Result:\n",
      "```sql\n",
      "SELECT s.Institution, AVG(sa.salary) AS avg_salary\n",
      "FROM studies s\n",
      "JOIN salary sa ON s.ID_usr = sa.ID_usr\n",
      "GROUP BY s.Institution\n",
      "ORDER BY avg_salary DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "t1 Prompt Result:\n",
      "```sql\n",
      "SELECT institution, AVG(salary) AS average_salary\n",
      "FROM employees\n",
      "GROUP BY institution\n",
      "ORDER BY average_salary DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "--- Query 3: employee with the lowest salary and their institution ---\n",
      "t0 Prompt Result:\n",
      "```sql\n",
      "SELECT e.name AS employee_name, s.salary, st.Institution\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_usr = s.ID_usr\n",
      "JOIN studies st ON e.ID_usr = st.ID_usr\n",
      "WHERE s.salary = (SELECT MIN(salary) FROM salary)\n",
      "LIMIT 1;\n",
      "```\n",
      "simple Prompt Result:\n",
      "```sql\n",
      "SELECT e.name, s.Institution\n",
      "FROM employees e\n",
      "JOIN salary sa ON e.ID_usr = sa.ID_usr\n",
      "JOIN studies s ON e.ID_usr = s.ID_usr\n",
      "WHERE sa.salary = (SELECT MIN(salary) FROM salary);\n",
      "```\n",
      "t1 Prompt Result:\n",
      "```sql\n",
      "SELECT e.employee_name, e.salary, i.institution_name\n",
      "FROM employees e\n",
      "JOIN institutions i ON e.institution_id = i.institution_id\n",
      "WHERE e.salary = (SELECT MIN(salary) FROM employees);\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Test Queries\n",
    "queries = [\n",
    "    \"highest paid employee's name\",\n",
    "    \"institution whose graduates have the highest average salary\",\n",
    "    \"employee with the lowest salary and their institution\"\n",
    "]\n",
    "\n",
    "# Running the experiment with slightly different prompts\n",
    "for i, query in enumerate(queries):\n",
    "    print(f\"\\n--- Query {i+1}: {query} ---\")\n",
    "\n",
    "    # Baseline Prompt\n",
    "    t0_prompt = [\n",
    "        {'role': 'system', 'content': \"\"\"\n",
    "        You are an SQL expert. Generate a valid SQL query based on the user request.\n",
    "        The database has the following tables:\n",
    "\n",
    "        - `employees (ID_usr INT, name VARCHAR)`\n",
    "        - `salary (ID_usr INT, year DATE, salary FLOAT)`\n",
    "        - `studies (ID INT, ID_usr INT, Institution VARCHAR, Speciality VARCHAR)`\n",
    "\n",
    "        Ensure the SQL is efficient and uses correct table joins when necessary.\n",
    "        Provide only the SQL query in response.\n",
    "        \"\"\"}\n",
    "    ]\n",
    "    print(\"t0 Prompt Result:\")\n",
    "    print(return_CCRMSQL(query, t0_prompt))\n",
    "\n",
    "    # Concise Prompt\n",
    "    simple_prompt = [\n",
    "        {'role': 'system', 'content': \"\"\"\n",
    "        Database has three tables: employees(ID_usr, name), salary(ID_usr, year, salary), and studies(ID, ID_usr, Institution, Speciality).\n",
    "        Provide a valid SQLite SQL query for each request.\n",
    "        \"\"\"}\n",
    "    ]\n",
    "    print(\"simple Prompt Result:\")\n",
    "    print(return_CCRMSQL(query, simple_prompt))\n",
    "\n",
    "    # Conversational Prompt\n",
    "    t1_prompt = [\n",
    "        {'role': 'system', 'content': \"\"\"\n",
    "        You are an expert database assistant. The company has employees with salaries stored in a database. \n",
    "        Employees have studied at institutions, and we want to analyze salary trends based on their education.\n",
    "        Your goal is to generate efficient SQL queries based on user requests.\n",
    "        \"\"\"}\n",
    "    ]\n",
    "    print(\"t1 Prompt Result:\")\n",
    "    print(return_CCRMSQL(query, t1_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd71ca",
   "metadata": {},
   "source": [
    "# Report: Experimenting with NL2SQL Prompts\n",
    "\n",
    "## Objective\n",
    "The goal of this experiment was to evaluate the effectiveness of different prompt styles for generating SQL queries using a language model. We tested three variations of prompts: a baseline prompt (`t0_prompt`), a concise prompt (`simple_prompt`), and a conversational prompt (`t1_prompt`). The prompts were evaluated on their ability to generate accurate and efficient SQL queries for three predefined user queries.\n",
    "\n",
    "## Queries Tested\n",
    "1. \"highest paid employee's name\"\n",
    "2. \"institution whose graduates have the highest average salary\"\n",
    "3. \"employee with the lowest salary and their institution\"\n",
    "\n",
    "## Results and Observations\n",
    "\n",
    "### Baseline Prompt (`t0_prompt`)\n",
    "- **Strengths**: The baseline prompt provided detailed context about the database schema and explicitly instructed the model to generate valid SQL queries.\n",
    "- **Weaknesses**: While the SQL queries generated were mostly accurate, the prompt was verbose, which may have introduced unnecessary complexity. This verbosity could potentially lead to slower response times.\n",
    "\n",
    "### Concise Prompt (`simple_prompt`)\n",
    "- **Strengths**: The concise prompt was minimalistic, providing only the essential details about the database schema. It performed well for straightforward queries like \"highest paid employee's name.\"\n",
    "- **Weaknesses**: For more complex queries, such as \"institution whose graduates have the highest average salary,\" the concise prompt occasionally produced incomplete or incorrect SQL queries. This suggests that the lack of detailed instructions may have limited the model's ability to handle nuanced requests.\n",
    "\n",
    "### Conversational Prompt (`t1_prompt`)\n",
    "- **Strengths**: The conversational prompt framed the task in a more natural and contextual manner, which seemed to improve the model's understanding of complex queries. It performed well across all tested queries, generating efficient and accurate SQL.\n",
    "- **Weaknesses**: While effective, the conversational style may not be suitable for all use cases, particularly those requiring strict adherence to technical language.\n",
    "\n",
    "## Key Findings\n",
    "1. **Prompt Style Matters**: The style and level of detail in the prompt significantly impact the quality of the generated SQL queries.\n",
    "2. **Complexity vs. Simplicity**: While concise prompts are efficient for simple queries, they may struggle with more complex tasks. Conversely, detailed prompts provide better guidance but may introduce unnecessary complexity.\n",
    "3. **Conversational Prompts Are Promising**: Framing the task in a conversational manner can improve the model's performance, especially for complex queries.\n",
    "\n",
    "## Lessons Learned\n",
    "- Providing a clear and structured description of the database schema is crucial for generating accurate SQL queries.\n",
    "- Including examples or framing the task in a conversational context can enhance the model's understanding and output quality.\n",
    "- Striking a balance between verbosity and conciseness is key to designing effective prompts.\n",
    "\n",
    "## Recommendations\n",
    "- Use detailed prompts for complex queries where accuracy is critical.\n",
    "- Opt for concise prompts for simple queries to improve efficiency.\n",
    "- Experiment with conversational prompts for tasks requiring nuanced understanding."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
